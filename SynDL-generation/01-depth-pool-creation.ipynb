{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import json\n",
    "import tarfile\n",
    "from random import randrange\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Passages Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSMARCO Collection v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Should add a code to check to downlaod if and only if the file is not exsit\n",
    "\n",
    "# url = 'https://msmarco.z22.web.core.windows.net/msmarcoranking/collection.tar.gz'\n",
    "# target_path = 'msmarco-collections/collection.tar'\n",
    "\n",
    "# response = requests.get(url, stream=True)\n",
    "# if response.status_code == 200:\n",
    "#     with open(target_path, 'wb') as f:\n",
    "#         f.write(response.raw.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tarfile.open('msmarco-collections/collection.tar', 'r') as tar:\n",
    "#         tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading TREC DL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2022\n",
    "nist_qrel_path = f\"./TREC-DL-{YEAR}/qrels-pass.txt\"\n",
    "results_path = f\"./TREC-DL-{YEAR}/passages-runs/\"\n",
    "test_queries_path = f\"./TREC-DL-{YEAR}/test-queries.tsv\"\n",
    "\n",
    "if YEAR in [2019, 2020, 2021]:\n",
    "    results_sep = '\\t'\n",
    "    passages_path = \"msmarco-collections/collection.tsv\"\n",
    "else:\n",
    "    results_sep = ' '\n",
    "    passages_path =  \"msmarco-collections/msmarco_v2_passage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386416, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading nist qrel file\n",
    "nist_qrel = pd.read_csv(nist_qrel_path, sep=' ', header=None, names=['qid', 'Q0', 'docid', 'rel'])\n",
    "nist_qrel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000511</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000719</td>\n",
       "      <td>42710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001532</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001908</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001975</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2055480</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2055634</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2055795</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2056158</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2056323</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        qid  docid\n",
       "0   2000511   1492\n",
       "1   2000719  42710\n",
       "2   2001532    369\n",
       "3   2001908    276\n",
       "4   2001975    406\n",
       "..      ...    ...\n",
       "71  2055480    329\n",
       "72  2055634    292\n",
       "73  2055795    387\n",
       "74  2056158    535\n",
       "75  2056323    271\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of passages per query\n",
    "nist_qrel.groupby('qid')['docid'].agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49627"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum number of passages for the query\n",
    "max(nist_qrel.groupby('qid')['docid'].agg('count').reset_index()['docid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of judged queries by NIST\n",
    "nist_judged_qids = set(nist_qrel['qid'])\n",
    "len(nist_judged_qids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Depth-10 Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 27.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>Q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_07_865649873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094518</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_44_338456978</td>\n",
       "      <td>2</td>\n",
       "      <td>0.092599</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_07_865676760</td>\n",
       "      <td>3</td>\n",
       "      <td>0.091848</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_17_149088917</td>\n",
       "      <td>4</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_07_865666439</td>\n",
       "      <td>5</td>\n",
       "      <td>0.089393</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_20_141207184</td>\n",
       "      <td>96</td>\n",
       "      <td>0.492810</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_04_584378445</td>\n",
       "      <td>97</td>\n",
       "      <td>0.488177</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_39_570179944</td>\n",
       "      <td>98</td>\n",
       "      <td>0.487391</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_20_142671399</td>\n",
       "      <td>99</td>\n",
       "      <td>0.487260</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_18_651004378</td>\n",
       "      <td>100</td>\n",
       "      <td>0.486001</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4874806 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           qid  Q0                         docid  rank     score  \\\n",
       "0      1006826  Q0  msmarco_passage_07_865649873     1  0.094518   \n",
       "1      1006826  Q0  msmarco_passage_44_338456978     2  0.092599   \n",
       "2      1006826  Q0  msmarco_passage_07_865676760     3  0.091848   \n",
       "3      1006826  Q0  msmarco_passage_17_149088917     4  0.089694   \n",
       "4      1006826  Q0  msmarco_passage_07_865666439     5  0.089393   \n",
       "...        ...  ..                           ...   ...       ...   \n",
       "49995   997700  Q0  msmarco_passage_20_141207184    96  0.492810   \n",
       "49996   997700  Q0  msmarco_passage_04_584378445    97  0.488177   \n",
       "49997   997700  Q0  msmarco_passage_39_570179944    98  0.487391   \n",
       "49998   997700  Q0  msmarco_passage_20_142671399    99  0.487260   \n",
       "49999   997700  Q0  msmarco_passage_18_651004378   100  0.486001   \n",
       "\n",
       "                   run_id  \n",
       "0                6systems  \n",
       "1                6systems  \n",
       "2                6systems  \n",
       "3                6systems  \n",
       "4                6systems  \n",
       "...                   ...  \n",
       "49995  SPLADE_ENSEMBLE_PP  \n",
       "49996  SPLADE_ENSEMBLE_PP  \n",
       "49997  SPLADE_ENSEMBLE_PP  \n",
       "49998  SPLADE_ENSEMBLE_PP  \n",
       "49999  SPLADE_ENSEMBLE_PP  \n",
       "\n",
       "[4874806 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading all submissions\n",
    "run_df_list = []\n",
    "for infile in tqdm(glob.glob(f'{results_path}/*')):\n",
    "    run_df = pd.read_csv(infile, sep='\\s+', header=None, names=['qid', 'Q0', 'docid', 'rank', 'score', 'run_id'])\n",
    "    run_df_list.append(run_df)\n",
    " \n",
    "all_submissions_df = pd.concat(run_df_list)\n",
    "all_submissions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4133806, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the queries that are judged by nist assessors\n",
    "all_submissions_df = all_submissions_df[~all_submissions_df['qid'].isin(nist_judged_qids)]\n",
    "all_submissions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "424\n"
     ]
    }
   ],
   "source": [
    "# no. of submission and no. of unjudged quereis\n",
    "print(len(set(all_submissions_df['run_id'])))\n",
    "print(len(set(all_submissions_df['qid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to be sure that judged queries are not included.\n",
    "set(all_submissions_df['qid']).intersection(nist_judged_qids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>Q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_07_865649873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094518</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_44_338456978</td>\n",
       "      <td>2</td>\n",
       "      <td>0.092599</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_07_865676760</td>\n",
       "      <td>3</td>\n",
       "      <td>0.091848</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_17_149088917</td>\n",
       "      <td>4</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1006826</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_07_865666439</td>\n",
       "      <td>5</td>\n",
       "      <td>0.089393</td>\n",
       "      <td>6systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49905</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_18_538727342</td>\n",
       "      <td>6</td>\n",
       "      <td>1.695422</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_39_454078645</td>\n",
       "      <td>7</td>\n",
       "      <td>1.659401</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49907</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_58_304621249</td>\n",
       "      <td>8</td>\n",
       "      <td>1.649428</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49908</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_58_304622289</td>\n",
       "      <td>9</td>\n",
       "      <td>1.647338</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49909</th>\n",
       "      <td>997700</td>\n",
       "      <td>Q0</td>\n",
       "      <td>msmarco_passage_48_450204918</td>\n",
       "      <td>10</td>\n",
       "      <td>1.592502</td>\n",
       "      <td>SPLADE_ENSEMBLE_PP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423986 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           qid  Q0                         docid  rank     score  \\\n",
       "0      1006826  Q0  msmarco_passage_07_865649873     1  0.094518   \n",
       "1      1006826  Q0  msmarco_passage_44_338456978     2  0.092599   \n",
       "2      1006826  Q0  msmarco_passage_07_865676760     3  0.091848   \n",
       "3      1006826  Q0  msmarco_passage_17_149088917     4  0.089694   \n",
       "4      1006826  Q0  msmarco_passage_07_865666439     5  0.089393   \n",
       "...        ...  ..                           ...   ...       ...   \n",
       "49905   997700  Q0  msmarco_passage_18_538727342     6  1.695422   \n",
       "49906   997700  Q0  msmarco_passage_39_454078645     7  1.659401   \n",
       "49907   997700  Q0  msmarco_passage_58_304621249     8  1.649428   \n",
       "49908   997700  Q0  msmarco_passage_58_304622289     9  1.647338   \n",
       "49909   997700  Q0  msmarco_passage_48_450204918    10  1.592502   \n",
       "\n",
       "                   run_id  \n",
       "0                6systems  \n",
       "1                6systems  \n",
       "2                6systems  \n",
       "3                6systems  \n",
       "4                6systems  \n",
       "...                   ...  \n",
       "49905  SPLADE_ENSEMBLE_PP  \n",
       "49906  SPLADE_ENSEMBLE_PP  \n",
       "49907  SPLADE_ENSEMBLE_PP  \n",
       "49908  SPLADE_ENSEMBLE_PP  \n",
       "49909  SPLADE_ENSEMBLE_PP  \n",
       "\n",
       "[423986 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating 10-depth pool based on the submissions rank of passages for each query\n",
    "depth_pool_samples = all_submissions_df[all_submissions_df['rank'].between(1, 10)]\n",
    "depth_pool_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dict from qid to docids\n",
    "qid_to_docids = defaultdict(set)\n",
    "\n",
    "for eachsample in depth_pool_samples.itertuples(index=True):\n",
    "    qid_to_docids[eachsample.qid].add(eachsample.docid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_to_num_passages = {k:len(v) for k, v in qid_to_docids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56443"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique passages/docids\n",
    "docids = set([item for sublist in qid_to_docids.values() for item in sublist])\n",
    "len(docids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n",
      "56475\n"
     ]
    }
   ],
   "source": [
    "# no. of queries and passages\n",
    "print(len(qid_to_num_passages.keys()))\n",
    "print(sum(qid_to_num_passages.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Passages/Dcouments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_bundles(bundlenum):\n",
    "def read_bundles_v1():\n",
    "    collection = open(passages_path, 'r').readlines()\n",
    "    for eachline in collection:\n",
    "        docid, passage = eachline.split('\\t')\n",
    "        docid = int(docid)\n",
    "        if docid in docids:\n",
    "            passages_bundles[docid] = passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bundles_v2(bundlenum):\n",
    "     with gzip.open(f'{passages_path}/msmarco_passage_{bundlenum}.gz','r') as fpassage:\n",
    "          for passage in fpassage:\n",
    "            json_passage = json.loads(passage.decode('utf8'))\n",
    "            if json_passage['pid'] in docids:\n",
    "                passages_bundles[json_passage['pid']] = json_passage['passage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_bundles = {}\n",
    "\n",
    "if YEAR in [2019, 2020, 2021]:\n",
    "    # read TREC 2019, 2020 passagess\n",
    "    read_bundles_v1()\n",
    "else:\n",
    "    for bundlenum in tqdm(range(0, 70)):\n",
    "        if bundlenum < 10:\n",
    "            bundlenum = f'0{str(bundlenum)}'\n",
    "        read_bundles_v2(bundlenum=bundlenum)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>588</td>\n",
       "      <td>1099 b cost basis i sell specific shares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9141</td>\n",
       "      <td>a boiled egg is how many calories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43905</td>\n",
       "      <td>average single person income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49712</td>\n",
       "      <td>behavior define</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58376</td>\n",
       "      <td>calculate btu per natural gas flow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                     query\n",
       "0    588  1099 b cost basis i sell specific shares\n",
       "1   9141         a boiled egg is how many calories\n",
       "2  43905              average single person income\n",
       "3  49712                           behavior define\n",
       "4  58376        calculate btu per natural gas flow"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_queries = pd.read_csv(test_queries_path, sep='\\t', header=None, names=['qid', 'query'])\n",
    "test_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict: qid to query\n",
    "queries = dict(zip(test_queries['qid'], test_queries['query']))\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_response(system_context: str, text: str):\n",
    "    \"\"\"\n",
    "    Generate a chat completion using OpenAI's chat completion API.\n",
    " \n",
    "    :param system_context: some context and/or instructions to the model\"\n",
    "    :param text: user message (aka prompt)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    openai.api_type = \"API-Type\"\n",
    "    openai.api_version = 'API-Version'\n",
    "    openai.api_base = 'API-Base-URL'\n",
    "    openai.api_key = 'Your-Key'\n",
    " \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-4-32k\", # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"{}\"\"\".format(system_context)\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.5,\n",
    "        presence_penalty=0,\n",
    "    )\n",
    " \n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_eval(system_context, user_prompt):\n",
    "\n",
    "    system_context = system_context\n",
    "    user_prompt = user_prompt\n",
    "    \n",
    "    try:\n",
    "        gpt_4_res = get_gpt_response(system_context=system_context, text=user_prompt)\n",
    "    except:\n",
    "        gpt_4_res = \"ERROR\"\n",
    "        # print(f\"gpt-4 ERROR: {e}\")\n",
    "\n",
    "    return gpt_4_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"You are a search quality rater evaluating the relevance of passages. Given a query and a passage, you must provide a score on an integer scale of 0 to 3 with the following meanings:\n",
    "\n",
    "3 = Perfectly relevant: The passage is dedicated to the query and contains the exact answer.\n",
    "2 = Highly relevant: The passage has some answer for the query, but the answer may be a bit unclear, or hidden amongst extraneous information.\n",
    "1 = Related: The passage seems related to the query but does not answer it.\n",
    "0 = Irrelevant: The passage has nothing to do with the query\n",
    "\n",
    "Assume that you are writing an answer to the query. If the passage seems to be related to the query but does not include any answer to the query, mark it 1. If you would use any of the information contained in the passage in such an asnwer, mark it 2. If the passage is primarily about the query, or contains vital information about the topic, mark it 3. Otherwise, mark it 0.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(query, passage):\n",
    "    return f\"\"\"Query\n",
    "    A person has typed [{query}] into a search engine.\n",
    "    \n",
    "    Result\n",
    "    Consider the following passage.\n",
    "    —BEGIN Passage CONTENT—\n",
    "    {passage}\n",
    "    —END Passage CONTENT—\n",
    "    \n",
    "    Instructions\n",
    "    Consider the underlying intent of the search, and decide on a final score of the relevancy of query to the passage given the context.\n",
    "    Score:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need during summarisation:\n",
    "gpt4_judgments = open(f\"all-queries-with-error/gpt4_judgments_all_queries_dl_{YEAR}.txt\", 'w')\n",
    "\n",
    "for qid, docids in tqdm(qid_to_docids.items()):\n",
    "    for docid in docids:\n",
    "        score = auto_eval(system_context=context, user_prompt=get_user_prompt(query=queries[qid], passage=passages_bundles[docid]))\n",
    "        print(score)\n",
    "        gpt4_judgments.write(f\"{qid} 0 {docid} {score}\\n\")\n",
    "    \n",
    "gpt4_judgments.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarisation Prompt: Error Cases for the Long Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_context = \"\"\"You are a summariser that summarises the passage to make it shorter but as much as relevant to the input passage.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_prompt(passage):\n",
    "    return f\"\"\"Return a very short relevant summary of the give passage:\n",
    "    Passage: {passage}\n",
    "    Summary:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56475/56475 [01:03<00:00, 896.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The write counter is: 56475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gpt4_qrel = open(\"gpt4_judgments_all_queries_dl_2022.txt\", 'r').readlines()\n",
    "rnd_index = open(\"gpt4_judgments_dl2022_random_index.txt\", 'w')\n",
    "\n",
    "write_counter = 0\n",
    "indices = set()\n",
    "\n",
    "with open(\"gpt4_judgments_dl2022_processed.txt\", 'w') as out_file:\n",
    "    for index, eachline in enumerate(tqdm(gpt4_qrel)):\n",
    "        qid, q0, docid, score = eachline.split(' ', 3)\n",
    "        score = score.strip('\\n')\n",
    "        \n",
    "        if len(score) == 1:\n",
    "            out_file.write(f\"{qid} 0 {docid} {score}\\n\")\n",
    "            write_counter += 1\n",
    "            indices.add(index)\n",
    "\n",
    "        elif score == \"ERROR\":\n",
    "            # passage = passages_bundles[int(docid)]\n",
    "            passage = passages_bundles[docid]\n",
    "            res_first = passage[0:len(passage)//2]\n",
    "            res_second = passage[len(passage)//2 if len(passage)%2 == 0 else ((len(passage)//2)+1):]\n",
    "\n",
    "            summarised_passage_1 = auto_eval(summary_context, get_summary_prompt(passage=res_first))\n",
    "            summarised_passage_2 = auto_eval(summary_context, get_summary_prompt(passage=res_second))\n",
    "            \n",
    "            if summarised_passage_1 == \"\" or summarised_passage_2 == \"\":\n",
    "                print(f\"NoSummarisedPassage - INDEX: {index}\")\n",
    "                rnd_index.write(f\"NoSummarisedPassage {index}\\n\")\n",
    "                out_file.write(f\"{qid} 0 {docid} {randrange(4)}\\n\")\n",
    "                write_counter += 1\n",
    "                indices.add(index)\n",
    "            else:\n",
    "                summarised_passage = summarised_passage_1 + ' ' + summarised_passage_2\n",
    "                new_score = auto_eval(system_context=context, user_prompt=get_user_prompt(query=queries[int(qid)], passage=summarised_passage))\n",
    "                if new_score == \"ERROR\":\n",
    "                    print(f\"NoLabelContextLength - INDEX: {index}\")\n",
    "                    rnd_index.write(f\"NoLabelContextLength {index}\\n\")\n",
    "                    out_file.write(f\"{qid} 0 {docid} {randrange(4)}\\n\")\n",
    "                    write_counter += 1\n",
    "                    indices.add(index)\n",
    "                else:\n",
    "                    out_file.write(f\"{qid} 0 {docid} {new_score}\\n\")\n",
    "                    write_counter += 1\n",
    "                    indices.add(index)\n",
    "        else:\n",
    "            print(f\"NoConditionApplied. Score: {score}\")\n",
    "            print(len(score))\n",
    "            out_file.write(f\"{qid} 0 {docid} {randrange(4)}\\n\")\n",
    "            write_counter += 1\n",
    "            indices.add(index)\n",
    "\n",
    "rnd_index.close()\n",
    "out_file.close()\n",
    "\n",
    "print(f\"The write counter is: {write_counter}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
